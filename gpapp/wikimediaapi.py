#coding:utf-8
#!/usr/bin/env python
"""
    Wikimedia API module
"""
from copy import deepcopy

from . import dataapi
from .googlemapsapi import GoogleMapsAddressProcessing

class WikiMediaAddressProcessing(dataapi.ApiWikiMedia):
    """
        creation of the address list of wikipedia pages
            - map_latitude
            - map_longitude
            generated by googlemap API
        determination of the content of the common wikimedia address
            at the address found by googlemap API
        display of the history for the googlemap address found
    """
    def __init__(self, address):
        super().__init__()
        self.api_data = dataapi.ApiDataConfig()
        self.coordinates = GoogleMapsAddressProcessing(address)
        self.map_address = self.coordinates.get_from_url_address_api()

    def get_from_address_list_creation(self):
        """
            common address list set found by wikimedia API
                - pages_wiki ==> wikimedia page address list set
                - common_address ==> set of wikimedia page address lists
        """
        _latitude =\
            self.map_address['address']['result']['geometry']['location']['lat']
        _longitude =\
            self.map_address['address']['result']['geometry']['location']['lng']
        latitude, longitude = _latitude, _longitude
        params = self.get_from_localization_data_api(latitude, longitude)
        address_url = self.api_data.get_from_url_json(params, self.url_api)
        common_address = [
            address_url['query']['geosearch'][page]['title'].split(' ')\
            for page in range(len(address_url['query']['geosearch']))
        ]
        return common_address

    def get_from_list_address_convertion(self):
        """
            converting the content
            of the address found by googleMap
            into a list of words
        """
        print(f'\naddress_conversion (wikiApi) = {self.map_address}')
        address = self.map_address['address']['result']['formatted_address']
        address_convert = address.lower().replace(',', '')
        converted_address_list = address_convert.split(' ')
        return converted_address_list

    def get_from_common_string_creation(self):
        """
            comparison of the result of the wikimedia API
            with the address of the googlemap API found
                - common_address ==> common address list
                - common_word    ==> common word list
                - word           ==> common address
        """
        # common_address_list = [... ['Quai', 'de', 'la', 'Gironde']...]
        common_address_list = self.get_from_address_list_creation()
        # googlemap_address = ['10','quai', 'de', 'la', 'charente'...]
        googlemap_address = self.get_from_list_address_convertion()
        common_addresses = [] # [...['quai', 'de', 'la', 'charente']...]
        common_words = [] # [...'quai', 'charente'...]
        compared_content = ''
        for address_as_a_list in common_address_list:
            for a_word in address_as_a_list:
                if a_word.lower() in googlemap_address:
                    common_words.append(a_word)
            common_addresses.append(deepcopy(common_words))
            common_words = []
        for an_address_as_a_list in common_addresses:
            if len(common_words )< len(an_address_as_a_list):
                compared_content = an_address_as_a_list
        compared_content = ' '.join(compared_content)
        return compared_content

    def get_from_page_url_api(self):
        """
            wikipedia API (Wikimedia) history search
            Result Ok
            {
                "batchcomplete": True,
                "query": {
                    "pages": [
                        {
                            "pageid": 4338589,
                            "ns": 0,
                            "title": "OpenClassrooms",
                            "extract": "OpenClassrooms est un site web de formation..."
                        }
                    ]
                }
            }
            wrong result
            {
                "batchcomplete": True,
                "query": {
                    "normalized": [
                        {
                            "fromencoded": False,
                            "from": "rueOpenClassrooms",
                            "to": "RueOpenClassrooms"
                        }
                    ],
                    "pages": [
                        {
                            "ns": 0,
                            "title": "RueOpenClassrooms",
                            "missing": True
                        }
                    ]
                }
            }
        """
        title = self.get_from_common_string_creation()
        params = self.get_from_page_data_api(title)
        page_url = self.api_data.get_from_url_json(params, self.url_api)
        try:
            page_url['query']['pages'][0]['extract'] != ''
        except KeyError:
            page_url = {
                'query': {
                    'pages': [
                        {
                            'missing': True
                        }
                    ]
                }
            }
        return page_url


if __name__ == '__main__':
    pass
